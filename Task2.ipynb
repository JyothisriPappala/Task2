{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86722684-f6dc-43b5-b3d6-48722d3078b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd38eefd-fca9-4ea8-be7b-595efc018dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "env_file = find_dotenv()\n",
    "load_dotenv(env_file, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b09c02-3237-4786-9398-7478c0159a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    import os\n",
    "    base_name, file_extension = os.path.splitext(file_path)\n",
    "    if file_extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file_path}')\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file_path}')\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif file_extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file_path)\n",
    "    else:\n",
    "        print('Unsupported document format!')\n",
    "        return None\n",
    "    document_data = loader.load()\n",
    "    return document_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392f38b5-6343-4813-9131-a72eba2e7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_from_wikipedia(search_query, language='en', max_docs_to_load=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    wiki_loader = WikipediaLoader(query=search_query, lang=language, load_max_docs=max_docs_to_load)\n",
    "    loaded_data = wiki_loader.load()\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fdfa4a-f70e-4231-913c-5e0ba9bd1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(document_data, chunk_length=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_length, chunk_overlap=0)\n",
    "    document_chunks = splitter.split_documents(document_data)\n",
    "    return document_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3d8b92-46d1-4643-bbf6-e7e93f6a2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_cost(documents):\n",
    "    import tiktoken\n",
    "    encoder = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    total_token_count = sum([len(encoder.encode(document.page_content)) for document in documents])\n",
    "    print(f'Total Tokens: {total_token_count}')\n",
    "    print(f'Embedding Cost in USD: {total_token_count / 1000 * 0.00002:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b920a75-82be-43ff-b29a-417a23170af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_or_store_embeddings(index_identifier, data_chunks):\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import ServerlessSpec\n",
    "    pinecone_client = pinecone.Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    embedding_model = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536, api_key=os.environ.get(\"OPEN_AI_KEY\"))\n",
    "    if index_identifier in pinecone_client.list_indexes().names():\n",
    "        print(f'Index {index_identifier} exists. Loading embeddings ... ', end='')\n",
    "        vector_store_instance = Pinecone.from_existing_index(index_identifier, embedding_model)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_identifier} and embeddings ...', end='')\n",
    "        pinecone_client.create_index(\n",
    "            name=index_identifier,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "        vector_store_instance = Pinecone.from_documents(data_chunks, embedding_model, index_name=index_identifier)\n",
    "        print('Ok')\n",
    "    return vector_store_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579f1bb8-e83b-48d8-ad1e-d81eece038a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pinecone_index(index_identifier='all'):\n",
    "    import pinecone\n",
    "    pinecone_client = pinecone.Pinecone()\n",
    "    if index_identifier == 'all':\n",
    "        index_list = pinecone_client.list_indexes().names()\n",
    "        print('Removing all indexes ... ')\n",
    "        for index in index_list:\n",
    "            pinecone_client.delete_index(index)\n",
    "        print('Done')\n",
    "    else:\n",
    "        print(f'Removing index {index_identifier} ...', end='')\n",
    "        pinecone_client.delete_index(index_identifier)\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7830c64d-a4ee-45ec-a795-685a955d0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_get_response(store, query, num_results=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    language_model = ChatOpenAI(model='gpt-3.5-turbo', temperature=1, api_key=os.environ.get(\"OPEN_AI_KEY\"))\n",
    "    retriever_instance = store.as_retriever(search_type='similarity', search_kwargs={'k': num_results})\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=language_model, chain_type=\"stuff\", retriever=retriever_instance)\n",
    "    response = qa_chain.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d91014-5a6a-4409-8b3f-49997d6f2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def split_content(data):\n",
    "    chunk_size = 1000  # Example chunk size\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "    return chunks\n",
    "data = \"This is some example text that we want to split into smaller chunks. \" * 50  # Example large text\n",
    "chunks = split_content(data)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b68dee85-00ed-4ad2-b9d9-a41306ee2003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated embedding cost: $0.0000\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def count_tokens(text, model=\"gpt-3.5\"):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n",
    "def calculate_embedding_cost(chunks, price_per_1000_tokens=0.0004):\n",
    "    total_tokens = 0\n",
    "    for chunk in chunks:\n",
    "        total_tokens += count_tokens(chunk)\n",
    "    total_cost = (total_tokens / 1000) * price_per_1000_tokens\n",
    "    return total_cost\n",
    "chunks = [\n",
    "    \"This is the first chunk of text. It's just an example to demonstrate how token counting works.\",\n",
    "    \"Here is the second chunk of text, another example with more content.\",\n",
    "    \"Finally, this is the third chunk of text to make sure we have multiple chunks for the demonstration.\"\n",
    "]\n",
    "cost = calculate_embedding_cost(chunks)\n",
    "print(f\"Estimated embedding cost: ${cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce221ba4-5cdf-45e6-963a-1a1ecd3c7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"Quit\" or \"Exit\" to exit the program.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "counter = 1\n",
    "print('Type \"Quit\" or \"Exit\" to exit the program.')\n",
    "while True:\n",
    "    user_question = input(f'Query #{counter}: ')\n",
    "    counter += 1\n",
    "    if user_question.lower() in ['quit', 'exit']:\n",
    "        print('Exiting... Goodbye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    response = ask_and_get_answer(vector_store, user_question)\n",
    "    print(f'\\nResponse: {response}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
